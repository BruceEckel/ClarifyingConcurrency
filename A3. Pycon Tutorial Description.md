> A workshop proposal for Pycon 2024

When you try to learn about concurrency from tutorials that claim to be “introductory,” does it seem like you’re already supposed to know a lot? Do the terms appear to mean different things depending on the article you’re reading? Do you get frustrated when you hear someone declare that “concurrency is easy?”

It’s not easy—it’s a minefield of different concepts, terminology, and curse-of-knowledge explanations. It’s a Catch-22: you can’t begin to understand concurrency until you know enough of the foundational principles to successfully navigate introductory tutorials.

This workshop gives you those foundational concepts. It creates the basic understanding framework so you’ll be able to read articles about concurrency and grasp what the authors are saying, regardless of the terminology they use or the specific implementation they may be describing.

It uses Python for examples, but the concepts are transferrable to other languages. The workshop assumes you are an intermediate Python programmer so you understand keywords and concepts, but you don’t need any background in concurrency.

- Concurrency is a leaky abstraction. Often you need to know operating system and hardware details to understand aspects.

## 1. Why are we doing this?
## 2. Performance alternatives
Before jumping into concurrency, consider other approaches to performance, as you might solve your problem much more easily and maintainably using a different solution. 
## 3. What is concurrency?
- Breaking programs into pieces (tasks)
- Time-slicing those tasks (scheduling)
- The context switch
- The tasks must somehow improve performance through this scheduling—but there’s no guarantee that they will.
- CPU bound problems and embarrassing parallelism.
- IO: anything that goes off-chip. IO bound and tasks waiting on other tasks.
## 4. How do programs run?
Assuming you have an operating system (you’re not doing embedded programming), all programs start with a process and one thread to drive that program forward. You need to understand this structure, as well as the reason for the Python Global Interpreter Lock (GIL), to properly imagine what’s going on and how to make choices, even if you’re only using coroutines (there’s always a thread under there, running your code).
## 5. What are threads good for?
Many languages allow you to run multiple threads simultaneously, which can make use of multiple cores to run programs faster. Python can also have multiple threads, but the GIL prevents these from executing simultaneously—so why do we even have them?  You'll learn that, even with the advent of coroutines, threads still solve an important problem. In addition, threads have left a problematic legacy.
## 6. Coroutines
- Suspension points by design rather than accident.
- The benefits of not saving the world:
- Context-switching size and speed
- Cancellation
- Error reporting
- The problem with coroutines: the library rewrite
## 7. Structured Concurrency
- What and why
- Python’s support for SC
## 8. Sharing
## 9. Architecture & Strategies




From [TREE-STRUCTURED CONCURRENCY](https://blog.yoshuawuyts.com/tree-structured-concurrency/)
- Under structured concurrency every task has a parent, cancellation flows downward, and errors flow upward. Completion guarantees no dangling tasks. 
- "A function will return when it's done, will cancel all work when you ask it to, and you'll always receive an error if there is something which needs handling. And as a result code under this model is **composable**."