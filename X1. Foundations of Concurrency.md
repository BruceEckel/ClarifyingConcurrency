> A workshop proposal for Pycon 2024

When you try to learn concurrency from tutorials that claim to be “introductory,” does it seem like you’re already supposed to know a lot? Do the terms appear to mean different things depending on the article you’re reading? Do you get frustrated when you hear someone declare that “concurrency is easy?”

It’s not easy—it’s a minefield of different concepts, terminology, and curse-of-knowledge explanations. It’s a paradox: you can’t begin to understand concurrency until you know enough of the foundational principles to successfully navigate introductory tutorials. In addition, concurrency is a “leaky abstraction“: you must often grasp operating system and hardware details.

This workshop teaches the foundational concepts needed to understand concurrency. It creates the basic  framework to enable you to read about concurrency and grasp what the authors are saying, regardless of the terminology they use or the specific implementation they may be describing.

It uses Python for examples, but the concepts are transferrable to other languages. The workshop assumes you are an intermediate Python programmer, so you understand keywords and concepts, but you don’t need any background in concurrency.
## 1. Why are we doing this?
The only reason to consider concurrency is performance—something about your program isn’t producing results fast enough to meet your needs. This includes not only raw data processing speed, but also the responsiveness of UI programs. Concurrency is only one strategy for solving performance problems, and it’s not necessarily the appropriate one, depending on your situation.
## 2. Performance alternatives
Performance tuning adds complexity to your program, which impacts the cost of creation and maintenance. You want to use the simplest approach you can to minimize these impacts and get *enough* performance to meet your needs. Before jumping into concurrency, consider other approaches to performance which might solve your problem more easily and maintainably:
- Using faster hardware can sometimes be the cheapest solution.
- Profiling shows where your code spends most of its time.
- You might be able to rewrite sections to improve performance.
- A library might fix your bottleneck.
- If that doesn’t work, you can create a Python module in a more performant language like Rust.
## 3. What is concurrency?
- Breaking programs into pieces (tasks).
- The context switch: suspending a task so other tasks can run.
- Time-slicing: driving those tasks forward a bit at a time (scheduling).
- Using tasks must somehow improve performance—but there’s no guarantee that they will.
- Parallelism for problems that require a lot of processing.
- IO: anything that uses an off-CPU system to produce a result. Because you are talking to another system, you don’t know how long it will take, what kind of failures might happen, and whether it will even respond to your request. Concurrency allows you to do other things when waiting on IO.
## 4. How do programs run?
Assuming you’re not doing embedded programming, you are running on an operating system. All programs start with a process to hold your program, memory and resources,  and one thread to drive that program forward. You need to understand this structure, as well as the reason for the Python Global Interpreter Lock (GIL), to properly imagine what’s going on and how to make choices, even if you’re using coroutines (there’s always a thread under there, running your code).
## 5. What are threads good for?
Many languages allow you to run multiple threads simultaneously, which can increase performance by making use of multiple cores. Python supports multiple threads, but the GIL prevents these from executing simultaneously—so why do we even have them?  You'll learn that, even with the advent of coroutines, threads still solve an important problem. In addition, threads have a problematic legacy.
## 6. Coroutines
Coroutines provide a different, and often much better, way to run tasks than threads. Threads are suspended by the operating system, at any time, which complicates the suspension process, adds overhead, and makes cancellation and error reporting difficult or impossible. Coroutines are suspended at known points that are visible in your code and used by the `asyncio` library to provide reliable cancellation and error reporting. The overhead of context-switching with coroutines is much smaller, so you can have orders of magnitude more coroutines than threads, and the context switch is much faster. There’s a downside to coroutines, however, which is that libraries must be rewritten to accommodate them, so your favorite library might not (yet) support coroutines.
## 7. Structured Concurrency
Structured concurrency is a foundational improvement, akin to the evolution from goto-based spaghetti code to programming with functions. For this reason, Python and some other programming languages have adopted support for structured concurrency. We learn why structured concurrency emerged, what it is, how it improves your concurrent programs, and the thorough support provided by the Python `asyncio` library, including scoped tasks, cancellation, and error handling.
## 8. Sharing Data
Sharing data between tasks is like sharing a lawnmower among neighbors. In some ways it’s more efficient, but you have to coordinate usage and deal with damage. We’ll look at some basic approaches for mitigating these issues, primarily immutability, resource locking, and ways to avoid sharing in the first place.
## 9. Architectures
One of the confusing aspects of concurrency is the numerous different kinds of problems that arise, and the different approaches for solving these problems. People commonly assume that the first approach they learn defines concurrency, and that becomes their worldview and point of reference when they talk about it, using the specific terminology and ideas of that approach. If you don’t have the big picture, listening to someone describe concurrency from their particular view is confusing, especially when the next person who talks about it has a different worldview.  It’s important to understand that concurrency is a collection of strategies. We’ll look at a few basic architectures to give you this bigger perspective.
